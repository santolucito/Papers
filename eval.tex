\subsection{Soundness and Completeness}\label{sound}

It is clear that no function will be returned by the algorithm that does not fit the examples given, since functions are validated before being reported. 
Therefore, it is trivial to conclude that \ourTool/ is sound over the given examples.
Still, it is possible for the synthesis procedure to return a function that does not capture the user's intent - that is, as with any programming by examples system, \ourTool/ is not sound over the user intent.
Generally, this ambiguity can be resolved by the user supplying more examples to narrow the set of possible fitting functions.
However, depending on what the user is trying to synthesize, and which examples have been provided, it is possible for new examples to increase the internal search space. 
If, for example, a user gives only positive examples for a \texttt{filter}, the refinement type predicate discovery will assume that the lists do not change size, and will likely return \texttt{map id} as a result.

The completeness claim we might like to make is that over the solution space defined in Section \ref{problem}, we will always find a solution if it exists.
Since our space is finite, completeness can be made trivially true by replacing all instances of pruning with a zero ranking, so that our algorithm now is only a best-first enumerative search.
Because we make some decisions in pruning that removes potentially sound functions, such as using the \codeinline{noRType} tag in Section \ref{HORtypeInf} we trade this completeness for performance.
In Section \ref{sec:related}, we will discuss why, even if we had completeness, it should be sacrificed in future work.
%On the other hand, the set of functions that the algorithm can produce is fairly broad. It is able to search through the entire space of higher order functions that have been specialized with a first-order function, when considering the functions that are in scope. We will see in Section \ref{evaluation} how broad this space actually is. \markk{See Section \ref{solnSpace}}


\subsection{Performance}

\begin{table*}[t]
  \centering
  \bgroup
  \def\arraystretch{1.1}
  \begin{tabular}{|c|l|c|l|l|l|l|}
    \hline
    & Name & Time (s) & Imports & \# Ex & Representative Example & Generated Function \\
    \hline
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Bool}}}
    & and & 2.02 & None & 3 & [True, False] $:\to$ False & all id \\
    & and-2 & 5.52 & None & 3 & [True, False] $:\to$ False & foldl min True \\
    & or  & 3.95 & None & 4 & [True, False] $:\to$ True & any id \\
    & xor & 5.59 & None & 4 & [True, False, True] $:\to$ False & foldl xor False \\
    \hline
    
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Tree (u.d.)}}}
    & double vals & 3.35 & None & 1 & ((1) 3 (2)) $:\to$ ((2) 6 (4)) & mapBTree (*2) \\
    & tree id & 2.49 & None & 1 & ((1) 3 ((4) 5 (6))) $:\to$ ((1) 3 ((4) 5 (6))) & mapBTree id \\
    & tree max & 2.95 & None & 3 & ((1 10) 5) $:\to$ 10 & accumTree max 0 \\
    & tree sum & 2.93 & None & 1 & ((3 1) 2) $:\to$ 6 & accumTree (+) 0 \\
    \hline
    
    \parbox[t]{2mm}{\multirow{9}{*}{\rotatebox[origin=c]{90}{List}}}
    & all even & 2.02 & Data.List & 4 & [2,4,6,8] $:\to$ True & all even \\
    & some odd & 4.70 & Data.List & 3 & [1,4,5,6] $:\to$ True & any odd \\
    & custom filter & 11.88 & Data.List & 3 & [1,2,3,4,5] $:\to$ [3,4,5] & filter user\_pred \\
    & length & 1.20 & Data.List & 3 & [5,6,7,8] $:\to$ 4 & foldl count 0 \\
    & max elem & 2.91 & Data.List & 3 & [4,10,7] $:\to$ 10 & foldl max 0 \\
    & negate all & 7.48 & Data.List & 1 & [True, False, True] $:\to$ [False, True, False] & map not \\
    & odd prefix & 8.77 & Data.List & 1 & [1,3,4,6,7] $:\to$ [1,3] & takeWhile odd \\
    & stutter & 3.02 & Data.List & 1 & [1,2,3] $:\to$ [1,1,2,2,3,3] & concatMap (replicate 2) \\
    & sum ints & 4.64 & Data.List & 1 & [1,2,3,4] $:\to$ 10 & foldl (+) 0 \\
    \hline
    
    \parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{Etc.}}}
    & set sum & 1.83 & Data.Map & 1 & \{ 1, 2, 3, 4 \} $:\to$ 10 & Data.Map.foldl (+) 0 \\
    & music id & 7.47 & Euterpea & 1 & C\# $:\to$ C\# & mMap id \\
    & transpose score & 5.15 & Euterpea & 1 & A $:\to$ B & mMap (trans 2) \\
    \hline
  \end{tabular}
  \egroup
  \caption{Benchmarks and Performance Measures. This table lists all 20 benchmarks, grouped by data structure. Each benchmark lists its name, the amount of time it took to synthesize, the extra imports it uses, the number of examples needed to synthesize, one representative example, and the synthesized function itself. The group marked ``Tree (u.d.)'' is a user-defined structure with user-defined higher-order operations. All reported data is generated on a Linux machine with four cores of Intel i5-3450 @ 3.10GHz and 8 Gb of ram.}
  \label{tab:benchmarks}
\end{table*}

In Table \ref{tab:benchmarks} we show detailed information about \ourTool/ over a set of benchmarks. These benchmarks were chosen to show the versatility of \ourTool/ over many different applications and libraries. The benchmarks over booleans, trees, and lists are common to many other programming-by-example tools. The examples that utilize the \codeinline{Data.List} and \codeinline{Euterpea} libraries to show \ourTool/'s ability to work with large, highly specialized, 3rd-party libraries. Due to the algorithm's focus on generating natural code, the synthesized functions are concise enough to be listed within the table itself. The representative examples show that few, simple hints to the synthesizer are able to produce good results. In many cases, the representative examples are actually the \textit{only} examples necessary to synthesize the desired function. This shows that our approach uses the information available to it effectively.

In addition, the runtime average about ten seconds thanks to the inherently parallel nature of the search. With just a few lines of code, we were able to achieve order-of-magnitude speedups over the serial version. Haskell's functional parallelism model is ideal for embarrassingly parallel problems like this one, and promises good scaling to larger instances of the problem over increasing computational resources.

In Section \ref{HORtypeInf} we discuss how type matching and the \codeinline{noRType} tag reduce the number of refinement type inferences we make. Recall that even if both types have a measure (lists and trees), in general there is no guarantee that this is a meaningful comparison. Since \lhask/ is the largest cost to our system in the offline stage, removing refinement type inference in these ambiguous cases provides a large performance gain. As an example, in processing the Haskell standard library \codeinline{base:Prelude}, 7 out of 30 higher order functions do not need to be checked against refinement types using this approach.


\subsection{Example Generation}\label{languageSupport}

We have tried to avoid code analysis at every stage of this paper.
However there are two points where this has fallen short. 
First, we must parse a file to extract the name and type information of every top level identifier. 
Second, using \lhask/ as a blackbox means that we are limited by \lhask/'s ability to deduce refinement types over functions. 
Our eventual goal is to create a system that can be easily ported across functional languages. 
Luckily, the first code dependency is small enough to handle with ease in most typed languages (the grammar of a type signature is relatively small). However \lhask/ is a powerful tool that would be difficult to recreate in another language. 

To this end, we can extend the refinement type system by allowing refinement type inference on representative examples of a higher order function.
We do not need to identify a particular component function since we are only interested in size based refinement types.
We then apply a similar refinement type inference strategy as in Listing \ref{exRTypeGen} to these examples.

Our current example generation tool uses QuickCheck to generate and apply many examples for higher order function Haskell~\cite{quickcheck}.
Of course, since \lhask/ supports so much of Haskell, this is not practically useful for us, but provides a prototype as a proof of concept.
Imagining that we could not find a refinement type directly on map, we might use examples to infer a refinement type. Take the following code:

\begin{lstlisting}[numbers=none]
map :: (a -> b) -> [a] -> [b]
map f [] = [] 
map f x:xs = f x : map f xs

mapExs = [[1,2,3] :-> [4,2,8]]
\end{lstlisting}

There are however repercussions to this approach. We are not guaranteed to generate a correct refinement type because we might not generate a fully representative examples. It then seems it is possible prune away many high order functions that are actually useful, but the full repercussions of this is outside the scope of this paper.


